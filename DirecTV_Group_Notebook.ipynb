{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1ir-7Bg8D7B"
      },
      "source": [
        "# DirecTV Group 1A: Next-Gen TV Show Recommendations\n",
        "\n",
        "by Safia, Mahsa, Serena, Caleb, and Jonathan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awKwXW-ym0nL"
      },
      "source": [
        "# Data Understanding\n",
        "\n",
        "### 1. Building the Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lykkNTgYRSD4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error \n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypag8qnklenf"
      },
      "source": [
        "Insert TMDB_tv_dataset_v3.csv to the files section of the Google Colab for access."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Tv7h8xXlR9A"
      },
      "outputs": [],
      "source": [
        "TMDB_filename = os.path.join(os.getcwd(), \"TMDB_tv_dataset_v3.csv\")\n",
        "df = pd.read_csv(TMDB_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv8rNAlTnAbE"
      },
      "source": [
        "### 2. Basic Exploration of TMDB Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KN125jOYnIND",
        "outputId": "4ee5b131-b134-4e4e-cac5-2f27ade88145"
      },
      "outputs": [],
      "source": [
        "#dataframe shape\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "GuDZCtVnnY4q",
        "outputId": "1251c240-5abd-400b-aa37-d9783e3c99cf"
      },
      "outputs": [],
      "source": [
        "#first few rows:\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "2_76pTosnbcx",
        "outputId": "02beee82-927e-44e2-af7f-eb6764cf4416"
      },
      "outputs": [],
      "source": [
        "#last few rows:\n",
        "display(df.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "9biV4VGYnfYC",
        "outputId": "82599df0-a4ec-404f-b43f-b9eacc8d1c32"
      },
      "outputs": [],
      "source": [
        "# display basic statistics of numeric columns\n",
        "display(df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "ml3zvEoFniuF",
        "outputId": "454ff334-2e41-4b83-ce6c-0cabfae82241"
      },
      "outputs": [],
      "source": [
        "# display info about DataFrame\n",
        "display(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGK3CW2LnlEq",
        "outputId": "a0293081-21ef-4c7a-b269-69259daa2f4c"
      },
      "outputs": [],
      "source": [
        "#identifying features\n",
        "df.columns.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSndGmu587Eo"
      },
      "source": [
        "# Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 828
        },
        "id": "yjmcGVic891c",
        "outputId": "af2f8745-691f-4fb6-cd0d-d56335a85c57"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "creating a corelation matrix with numeric data\n",
        "'''\n",
        "numeric_data = df.select_dtypes(include='number')\n",
        "corr_matrix = numeric_data.corr()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPVn1_-u9atZ"
      },
      "source": [
        "### Correlation Matrix Insights\n",
        "* 'number_of_seasons' and 'number_of_episodes' have a correlation of 0.42. This shows us that we have a moderately positive correlation, which makes sense since a show with more seasons tends to have more episodes\n",
        "* 'vote_count' and 'popularity' have a correlation of 0.22, which is a weak positive correlation. This means that shows with more votes are slighly more popular, but it is not a strong relationship\n",
        "* 'number_of_episodes' and 'popularity' have a correlation of 0.34, which is a moderatly positive correlation. This means that shows with more episodes tend to be more popular\n",
        "* 'vote_average' and 'episode_run_time' have a correlation of 0.16, which is a weak positive corelation. This could mean that longer-running episodes might have a slightly higher average rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ysr3nDOa9hx9",
        "outputId": "b1285309-6c74-4044-e1e1-281e35ff3fbb"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "creating a pair plot to examine the pairwise relationships between multiple features\n",
        "'''\n",
        "sns.pairplot(df[['number_of_seasons', 'number_of_episodes', 'vote_count', 'vote_average', 'popularity', 'episode_run_time']], diag_kind='kde')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT1DBH_Y9k_q"
      },
      "source": [
        "### Pair Plot Insights\n",
        "* The scatter plots off the diagonal represent a relationship between two variables, while the diagonal plots show the distribution of a single varaible\n",
        "* 'number_of_seasons' and 'number_of_episodes' have more of a linear relationship since shows with more seasons mostly have more episodes\n",
        "* there are many distributions (like 'number_of_seasons' and 'vote_count') that are heavily skewed, with a large number of shows having a low count and only a few having very high values\n",
        "* outliers are visible, like 'number_of_episodes' vs. 'vote_count' has some shows with a significantly high vote count compared to others"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "shSArzId9oWo",
        "outputId": "8a9c5afb-b947-469f-cef6-758c111e863e"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "histogram and KDE for vote_agerage\n",
        "'''\n",
        "sns.histplot(df['vote_average'], kde=True, bins=20)\n",
        "plt.title('Distribution of IMDB Vote Averages')\n",
        "plt.xlabel('Vote Average')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "BS4Mltmp9qeK",
        "outputId": "f525dead-b259-4a5f-f85a-97c91dd649a8"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "boxplot to compare vote_average by number_of_episodes by first creating bins for the vote_average\n",
        "'''\n",
        "\n",
        "labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # modify bins to include 10\n",
        "bins = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]  # 12 edges, include a bin for values 10-11\n",
        "\n",
        "df['vote_average_binned'] = pd.cut(df['vote_average'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "sns.boxplot(x='vote_average_binned', y='number_of_episodes', data=df)\n",
        "plt.title('IMDB Vote Average (Binned) by Number of Episodes')\n",
        "plt.xticks(rotation=45)\n",
        "plt.xlabel('Vote Average (Binned)')\n",
        "plt.ylabel('Number of Episodes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P95xw7qg_f2Q"
      },
      "source": [
        "## Visualizing Distributions (Histograms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQjzj140_Z07"
      },
      "outputs": [],
      "source": [
        "numerical_columns = ['number_of_seasons', 'number_of_episodes', 'vote_count', 'vote_average', 'popularity', 'episode_run_time']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "NbyPTuNd_cUZ",
        "outputId": "b9d7dbd4-90cf-4381-bd0f-1b587878ccd7"
      },
      "outputs": [],
      "source": [
        "df[numerical_columns].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "l1Iw_c-j_mzx",
        "outputId": "542ae80f-d18b-4f16-ac9b-95bf8e8d0a14"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# Regular Histograms\n",
        "\n",
        "df[numerical_columns].hist(figsize=(12, 10), bins=15)\n",
        "plt.suptitle('Histograms of Numerical Columns')\n",
        "plt.show()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930
        },
        "id": "0I_CJF8F_pxQ",
        "outputId": "bdd38f19-5f6f-49d5-f0ee-a7e7473d1e6f"
      },
      "outputs": [],
      "source": [
        "# Filter the DataFrame so it is easier to visualize without outliers\n",
        "filtered_df = df[\n",
        "    (df['number_of_seasons'] < 10) &\n",
        "    (df['number_of_episodes'] < 100) &\n",
        "    (df['vote_count'] < 100) &\n",
        "    (df['popularity'] < 100) &\n",
        "    (df['episode_run_time'] < 100)\n",
        "]\n",
        "\n",
        "# Plotting the histograms for the filtered data\n",
        "filtered_df[['number_of_seasons', 'number_of_episodes', 'vote_count', 'vote_average', 'popularity', 'episode_run_time']].hist(\n",
        "    figsize=(12, 10), bins=15)\n",
        "\n",
        "plt.suptitle('Histograms of Numerical Columns (Filtered)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJfJGBZXAi5-"
      },
      "source": [
        "### Histogram Insights\n",
        "\n",
        "- The histograms indicate that most of the numerical columns in the dataset have highly skewed distributions. (i.e, 'number_of_seasons' and 'number_of_episodes'  are clearly right-skewed)\n",
        "\n",
        "- A small number of extreme values dominate the range indicating that outliers are present.\n",
        "\n",
        "- We must deal with this to improve our models, so we should do log transformation and look at the outliers to see if we should discard them.\n",
        "\n",
        "- **Feature Engineering Suggestions**: Log Transformation of numerical columns to potentially aid in skewness\n",
        "\n",
        "- **Pre-processing Suggestions**: Outlier Analysis to improve predictive performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgJdQfwvCpqG"
      },
      "source": [
        "## Distribution of TV-Shows without Zeroes + Understanding Amount of Zeross in Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930
        },
        "id": "5rUyMUwMCso-",
        "outputId": "c6bb8a5b-93a7-4a80-8439-43b1c0a826ae"
      },
      "outputs": [],
      "source": [
        "# Replace zeros with NaN to exclude them temporarily\n",
        "df_nonzero = filtered_df[numerical_columns].replace(0, np.nan)\n",
        "df_nonzero.hist(figsize=(12, 10), bins=50)\n",
        "plt.suptitle('Histograms of Log-Transformed Numerical Columns (Excluding Zeros)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CogVuG3KDLE3",
        "outputId": "f9141a5d-e6f9-4308-ec7c-0583ead2afe3"
      },
      "outputs": [],
      "source": [
        "threshold = 0.001\n",
        "\n",
        "near_zero_counts = {}\n",
        "\n",
        "for col in numerical_columns:\n",
        "    count_near_zero = df[df[col] <= threshold].shape[0]\n",
        "    percentage_near_zero = (count_near_zero / df.shape[0]) * 100\n",
        "    near_zero_counts[col] = {'count': count_near_zero, 'percentage': percentage_near_zero}\n",
        "\n",
        "near_zero_df = pd.DataFrame.from_dict(near_zero_counts, orient='index')\n",
        "near_zero_df.columns = ['Count Near Zero (below 0.001)', 'Percentage Near Zero']\n",
        "\n",
        "print(near_zero_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TE4V1ZjIRKu"
      },
      "source": [
        "## Outlier Analysis (Using Interquartile Method)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9G9o-ZqIQZT",
        "outputId": "80ef4ccb-45c3-4131-8c15-f28de3cbba96"
      },
      "outputs": [],
      "source": [
        "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
        "Q1 = df[numerical_columns].quantile(0.25)\n",
        "Q3 = df[numerical_columns].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define outliers as points below Q1 - 1.5*IQR or above Q3 + 1.5*IQR\n",
        "outliers = ((df[numerical_columns] < (Q1 - 1.5 * IQR)) | (df[numerical_columns] > (Q3 + 1.5 * IQR)))\n",
        "\n",
        "# Number of outliers in each column\n",
        "outliers_count = outliers.sum()\n",
        "print(\"Number of Outliers in each column: \\n\", outliers_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi4Z8_JeI-bS"
      },
      "source": [
        "- Suggestions: Winsorize outliers after log transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMHO36bQntgL"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By72rPZ_n0Zl"
      },
      "source": [
        "### Handle Missing Values  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-enK6ionv7t",
        "outputId": "16f40b04-cab4-4bad-c0aa-18f5b85c6282"
      },
      "outputs": [],
      "source": [
        "# Inspect the structure of the data\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoPxeURXrUCQ",
        "outputId": "49da4b4f-f425-4936-e685-621450516ffd"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BTc6HuVrVbT",
        "outputId": "3f3ce234-8177-4189-e659-d0df113fda70"
      },
      "outputs": [],
      "source": [
        "# Verify the data types of all columns\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFulnP3LrbmV"
      },
      "outputs": [],
      "source": [
        "# Fill missing values for numerical columns with mean\n",
        "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqq4xjWwrd3p"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "the changes I made here are that I filter out the 'object' data types and then check to see if it is not the\n",
        "'genres' column. if it is not, then I add it to the 'columns_to_fill\" list. this is because I am labeling\n",
        "shows without a genre as 'Unknown' in the one-hot encoding step. then after that, I apply the mode of the\n",
        "specific column to the missing value for now.\n",
        "'''\n",
        "\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "columns_to_fill = [col for col in categorical_cols if col != 'genres']\n",
        "df[columns_to_fill] = df[columns_to_fill].apply(lambda col: col.fillna(col.mode()[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw9IKmG6rgdl",
        "outputId": "2bb71ab7-fda5-4a74-921d-49c2adbaa1e7"
      },
      "outputs": [],
      "source": [
        "# Verify that there are no missing values\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Yn2zh6tn2nj"
      },
      "source": [
        "### Remove Duplicates  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srKmlG3N0ywy"
      },
      "source": [
        "1,580 rows of data were removed due to it being a duplicate row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuEC5Gnz1UWb",
        "outputId": "161d886a-1da0-4c86-9717-720cb1a1a636"
      },
      "outputs": [],
      "source": [
        "# Check how many duplicates are there\n",
        "num_duplicate_rows = df.duplicated().sum()\n",
        "print(f\"Number of duplicate rows: {num_duplicate_rows}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPIWTsdW1fhU"
      },
      "outputs": [],
      "source": [
        "# Remove duplicates\n",
        "df = df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPXqO7Ww1jE9",
        "outputId": "4c3df789-2cef-429f-b9dc-e20bedce78a4"
      },
      "outputs": [],
      "source": [
        "num_duplicates_after = df.duplicated().sum()\n",
        "print(f\"Number of duplicates after removing: {num_duplicates_after}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JFbKwEGn5NJ"
      },
      "source": [
        "### Clean Text Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "IectzYdJn8wO",
        "outputId": "89c83528-7986-4876-97da-99eaceafafbb"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "I made some notes on how to get nltk to work on your enviroment, I know that this has worked on VS Code\n",
        "on macOS so if that is the enviroment and OS that you are using this should work. I hope it helps!\n",
        "\n",
        "how to install nltk:\n",
        "1. make sure you are working in a virtual enviroment when working on vs code, also\n",
        "ensure you have python installed with the following command:\n",
        "python --version\n",
        "\n",
        "2. on macos, run this command to create the virtual enviroment:\n",
        "python3 -m venv myenv\n",
        "\n",
        "3. then activate the virtual enviroment with this command:\n",
        "source myenv/bin/activate\n",
        "\n",
        "4. then you can install packages like nltk with this command:\n",
        "pip install nltk\n",
        "\n",
        "5. once you have done this, check to see if nltk have been dowloaded with this command:\n",
        "pip list\n",
        "nltk should show up in the list\n",
        "\n",
        "6. then in the terminal type in 'python3', then 'import nltk', then nltk.__version__, this will help\n",
        "ensure that nltk is installed\n",
        "\n",
        "7. then I ensured I have actually activated the virtual enviroment with this command, this\n",
        "will be different depending on which directory your enviroment is located:\n",
        "source /Users/safiaboutaleb/Developer/directv_tvrec/myenv/bin/activate\n",
        "\n",
        "8. then I tried to reinstall the certificates with this command for nltk to finally work:\n",
        "/Applications/Python\\ 3.11/Install\\ Certificates.command\n",
        "\n",
        "The following lines of code below here are needed to install the nessesary components of nltk,\n",
        "once you run this once, you can delete these lines of code because they will have already been installed:\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "yt video that helped a bit:\n",
        "https://www.youtube.com/watch?v=85Xr0UGR8qQ\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64E8W0nNsVO_",
        "outputId": "27003b1a-68a9-467e-87a3-0fb0e656a835"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0J71NzcVTAI"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "clean text function to convert text to lowercase, remove special characters\n",
        "(punctuation, numbers, etc.), remove stop words, tokenize, and apply lemmatization\n",
        "'''\n",
        "\n",
        "def clean_text(text):\n",
        "  text = text.lower()\n",
        "\n",
        "  text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "  tokens = word_tokenize(text)\n",
        "\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "  cleaned_text = ' '.join(tokens)\n",
        "\n",
        "  return cleaned_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiL5lev5VTAI"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "now we use the clean_text function on the overview column\n",
        "'''\n",
        "df['cleaned_overview'] = df['overview'].apply(lambda x: clean_text(x) if pd.notnull(x) else '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p42k3nTBVTAI",
        "outputId": "c5ed742a-5256-4592-9467-86d11168cedd"
      },
      "outputs": [],
      "source": [
        "print(df['cleaned_overview'][0])\n",
        "print(df['overview'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlDXwm6TVTAJ"
      },
      "outputs": [],
      "source": [
        "df = df.drop('overview', axis=1) # drop the original 'overview' column and save the chagnes to the csv file\n",
        "df.to_csv('TMDB_tv_dataset_v3.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFYHa_HYoBM3"
      },
      "source": [
        "### One-Hot Encoding of Categorical Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya3CFgkyVTAJ"
      },
      "source": [
        "* Genre One-Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ2QhuGeVTAJ"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "my plan here is to just split each genre as a token by using the comma as a delimiter, then find all\n",
        "of the unique genres, and then one-hot encode them so I can drop the original genres column\n",
        "'''\n",
        "\n",
        "df['genres'] = df['genres'].fillna('Unknown') # for genres that are empty just call them Unknown\n",
        "\n",
        "df['genres'] = df['genres'].apply(lambda x: x.split(', '))\n",
        "\n",
        "unique_genres = sorted(set(genre for genres in df['genres'] for genre in genres))\n",
        "\n",
        "for genre in unique_genres:\n",
        "  df[genre] = df['genres'].apply(lambda genres: int(genre in genres))\n",
        "\n",
        "df = df.drop('genres', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPa3m_ytVTAJ"
      },
      "outputs": [],
      "source": [
        "# now here I can save the modifications to the csv file\n",
        "df.to_csv('TMDB_tv_dataset_v3.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWK1qcOEVTAJ"
      },
      "source": [
        "* Rest of the One-Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5c1ZRr0oDaS",
        "outputId": "8e09b700-49ff-41b1-a748-142713ebcc5c"
      },
      "outputs": [],
      "source": [
        "# Creating a list of all columns with object values and inspecting their unique values\n",
        "list = df.select_dtypes(include=['object']).columns.tolist()\n",
        "print(df[list].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKCfUEi0VTAJ"
      },
      "outputs": [],
      "source": [
        "# Columns not included are name, overview, backdrop_path, homepage, original_name, poster_path, tagline, languages, spoken_languages,production_countries, and cleaned_overview\n",
        "encode_cols =['original_language','type', 'status','created_by','networks','origin_country','production_companies']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMATpN5kVTAQ",
        "outputId": "16afceaa-2fcf-4ef0-8da2-0adad5ce95f8"
      },
      "outputs": [],
      "source": [
        "# Creating a list of the top 20 values in the original_language column\n",
        "top_20_original_language = df['original_language'].value_counts(ascending = False).head(20).index.tolist()\n",
        "top_20_original_language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwV__AtjVTAQ"
      },
      "outputs": [],
      "source": [
        "# Creating one-hot encoded columns for original_language\n",
        "for i in top_20_original_language:\n",
        "    name = 'original-language_' + i\n",
        "    df[name] = np.where(df['original_language'] == i, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMHT9IbEVTAQ",
        "outputId": "8522aabd-8ecc-4957-e8d2-8115a3e7c4ae"
      },
      "outputs": [],
      "source": [
        "# Removing the original_language column from df and encode_cols\n",
        "df.drop(columns = ['original_language'], inplace = True)\n",
        "encode_cols.remove('original_language')\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHXh_TDyVTAQ",
        "outputId": "074cf5de-0418-4dc8-c365-ac8982fdccd3"
      },
      "outputs": [],
      "source": [
        "# Creating a list of the top 10 values in the created_by column\n",
        "top_10_created_by = df['created_by'].value_counts(ascending = False).head(10).index.tolist()\n",
        "top_10_created_by"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3esiGh7VTAQ"
      },
      "outputs": [],
      "source": [
        "# Creating one-hot encoded columns for created_by\n",
        "for i in top_10_created_by:\n",
        "    name = 'created-by_' + i\n",
        "    df[name] = np.where(df['created_by'] == i, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkIXQnNYVTAR",
        "outputId": "5c4884d4-2dcf-49c6-f25b-9b38cf1e328e"
      },
      "outputs": [],
      "source": [
        "# Removing the created_by column from df and encode_cols\n",
        "df.drop(columns = ['created_by'], inplace = True)\n",
        "encode_cols.remove('created_by')\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTpkGnugVTAR",
        "outputId": "1b2310c4-102f-4cbc-aa2f-db9c356af0e5"
      },
      "outputs": [],
      "source": [
        "# Creating a list of the top 11 values in the networks column\n",
        "top_11_networks = df['networks'].value_counts(ascending = False).head(11).index.tolist()\n",
        "top_11_networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBDjiaJRVTAR"
      },
      "outputs": [],
      "source": [
        "# Creating one-hot encoded columns for networks\n",
        "for i in top_11_networks:\n",
        "    name = 'networks_' + i\n",
        "    df[name] = np.where(df['networks'] == i, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A_ro0CcVTAR",
        "outputId": "09df3ff6-9ebe-406b-c173-4bfcb765f306"
      },
      "outputs": [],
      "source": [
        "# Removing the networks column from df and encode_cols\n",
        "df.drop(columns = ['networks'], inplace = True)\n",
        "encode_cols.remove('networks')\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1xUg7HwVTAR",
        "outputId": "6331fb67-b471-4189-a3f8-abd3caa2df67"
      },
      "outputs": [],
      "source": [
        "# Creating a list of the top 10 values in the origin_country column\n",
        "top_26_origin_country = df['origin_country'].value_counts(ascending = False).head(26).index.tolist()\n",
        "top_26_origin_country"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJA8wJg5VTAR"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "I was getting a warning message when running the code due to performance issues, so I followed\n",
        "the warnings sudgested approach to fix the issue by using the pd.concat function.\n",
        "'''\n",
        "\n",
        "one_hot_encoded_origin_country = pd.DataFrame() # start with an empty dataframe\n",
        "\n",
        "for i in top_26_origin_country:\n",
        "    one_hot_encoded_origin_country['origin-country_' + i] = np.where(df['origin_country'] == i, 1, 0)\n",
        "\n",
        "# the we can concatenate the one-hot encoded columns to the original DataFrame\n",
        "df = pd.concat([df, one_hot_encoded_origin_country], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ18dR4IVTAR",
        "outputId": "3cf0d37e-5582-4ed8-a116-8fcea1d69ca1"
      },
      "outputs": [],
      "source": [
        "# Removing the origin_country column from df and encode_cols\n",
        "df.drop(columns = ['origin_country'], inplace = True)\n",
        "encode_cols.remove('origin_country')\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjnbHKvaVTAR",
        "outputId": "0727b892-2fb2-41cb-c205-834e8a0a77ec"
      },
      "outputs": [],
      "source": [
        "# Creating a list of the top 10 values in the production_companies column\n",
        "top_10_production_companies = df['production_companies'].value_counts(ascending = False).head(10).index.tolist()\n",
        "top_10_production_companies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcmM2K-9VTAR"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "did the same changes to this code cell as well to fix the warning message\n",
        "'''\n",
        "\n",
        "one_hot_encoded_production_companies = pd.DataFrame() # start with an empty dataframe\n",
        "\n",
        "for i in top_26_origin_country:\n",
        "    one_hot_encoded_production_companies['production-companies_' + i] = np.where(df['production_companies'] == i, 1, 0)\n",
        "\n",
        "# the we can concatenate the one-hot encoded columns to the original DataFrame\n",
        "df = pd.concat([df, one_hot_encoded_production_companies], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OwJ0kqzVTAR",
        "outputId": "225843b0-c004-4fd0-c4f0-6e12abd5fe35"
      },
      "outputs": [],
      "source": [
        "# Removing the production_companies column from df and encode_cols\n",
        "df.drop(columns = ['production_companies'], inplace = True)\n",
        "encode_cols.remove('production_companies')\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7GQI2hJVTAR",
        "outputId": "629ca15f-5643-4611-a2bb-c3c8fba7588c"
      },
      "outputs": [],
      "source": [
        "# One-hot encoding remaining columns\n",
        "for colname in encode_cols:\n",
        "    df_encoded = pd.get_dummies(df[colname], prefix=colname+'')\n",
        "    df = df.join(df_encoded)\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lpvs8erzVTAR",
        "outputId": "e03ba08e-56f2-4d4c-cd45-7d516815aa1e"
      },
      "outputs": [],
      "source": [
        "# Removing remaining original cols from df\n",
        "df.drop(columns=encode_cols,axis=1,inplace=True)\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "x2c71e9qVTAR",
        "outputId": "86341c6b-4f0b-4ad0-ea34-21e7f75b4004"
      },
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5rzt2i7RztX",
        "outputId": "ab0f3ed0-8fe7-4d93-c585-a8d10bf18094"
      },
      "outputs": [],
      "source": [
        "# Converting first_air_date and last_air_date columns to DateTime referring to https://www.youtube.com/watch?v=f7LODKIjtaA\n",
        "df['first_air_date'] = pd.to_datetime(df['first_air_date'], format = '%Y-%m-%d')\n",
        "df['last_air_date'] = pd.to_datetime(df['last_air_date'], format = '%Y-%m-%d' )\n",
        "print(df['first_air_date'].dtypes)\n",
        "print(df['last_air_date'].dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsHYI97UR2LJ",
        "outputId": "41b3ddb8-c89d-465c-ef4e-6d4a21e81180"
      },
      "outputs": [],
      "source": [
        "print(df['first_air_date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ0oFrfIR4Qu",
        "outputId": "5bb12390-4899-4703-c576-cb9d74df6c82"
      },
      "outputs": [],
      "source": [
        "print(df['last_air_date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDP0naK2R7Ry"
      },
      "outputs": [],
      "source": [
        "# Creating a function to create seasons for each month\n",
        "def get_season(date):\n",
        "    month = date.month\n",
        "    if month in [12, 1, 2]:\n",
        "        return 'WINTER'\n",
        "    elif month in [3, 4, 5]:\n",
        "        return 'SPRING'\n",
        "    elif month in [6, 7, 8]:\n",
        "        return 'SUMMER'\n",
        "    elif month in [9, 10, 11]:\n",
        "        return 'FALL'\n",
        "    else:\n",
        "        return 'UNKNOWN'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "LpDfMNAlR9h9",
        "outputId": "4e257692-1285-4dd0-da16-766d018545a4"
      },
      "outputs": [],
      "source": [
        "# Creating a column with the seasons for first_air_date\n",
        "df['first_air_date_season'] = df['first_air_date'].apply(get_season)\n",
        "df['first_air_date_season']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBG9brW1SBDN",
        "outputId": "d9f72d3c-ddd5-4540-9e72-be1067246d77"
      },
      "outputs": [],
      "source": [
        "# Creating columns for first_air_date_season as boolean values\n",
        "df['first_air_date_winter'] = df['first_air_date_season'] == 'WINTER'\n",
        "df['first_air_date_spring'] = df['first_air_date_season'] == 'SPRING'\n",
        "df['first_air_date_summer'] = df['first_air_date_season'] == 'SUMMER'\n",
        "df['first_air_date_fall'] = df['first_air_date_season'] == 'FALL'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7eiiEW6SD9v"
      },
      "outputs": [],
      "source": [
        "# Drop the first_air_date_season and first_air_date columns if necessary\n",
        "# df.drop('first_air_date_season', axis = 1, inplace = True)\n",
        "# df.drop('first_air_date', axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "bqK8Ckv4SFhv",
        "outputId": "aa9de63c-bbf2-4832-d7a5-447538b60a88"
      },
      "outputs": [],
      "source": [
        "# Repeating same process for last_air_date\n",
        "df['last_air_date_season'] = df['last_air_date'].apply(get_season)\n",
        "df['last_air_date_season']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYGEZxwXSHlc",
        "outputId": "13672df0-58f4-4ff0-98ed-f8fd86cf43e3"
      },
      "outputs": [],
      "source": [
        "df['last_air_date_winter'] = df['last_air_date_season'] == 'WINTER'\n",
        "df['last_air_date_spring'] = df['last_air_date_season'] == 'SPRING'\n",
        "df['last_air_date_summer'] = df['last_air_date_season'] == 'SUMMER'\n",
        "df['last_air_date_fall'] = df['last_air_date_season'] == 'FALL'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0az7R-vSJLE"
      },
      "outputs": [],
      "source": [
        "# Drop the last_air_date_season and last_air_date columns if necessary\n",
        "# df.drop('last_air_date_season', axis = 1, inplace = True)\n",
        "# df.drop('last_air_date', axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "f2MGdwALSK3U",
        "outputId": "dc86bb4a-90c1-4091-9f71-e1996284ba0b"
      },
      "outputs": [],
      "source": [
        "# Inspecting columns to ensure process was done correctly\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gTHCz23cVzT"
      },
      "source": [
        "## Log Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xROJBK7xt7sS"
      },
      "outputs": [],
      "source": [
        "#Since a lot of columns were made after one hot encoding, I had to reference the original numerical columns\n",
        "numerical_columns = ['number_of_seasons', 'number_of_episodes', 'vote_count', 'vote_average', 'popularity', 'episode_run_time']\n",
        "\n",
        "# Apply log transformation to reduce skewness\n",
        "df_log = df[numerical_columns].apply(lambda x: np.log1p(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "iSfENCbCqEIh",
        "outputId": "0f1ed355-c2f3-40df-bfed-a4b301c830fe"
      },
      "outputs": [],
      "source": [
        "df_log[numerical_columns].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930
        },
        "id": "DrJA4tFVieSc",
        "outputId": "0035b8c1-72a5-4b63-b016-68441f365557"
      },
      "outputs": [],
      "source": [
        "# Plotting histograms after log transformation\n",
        "df_log.hist(figsize=(12, 10), bins=15)\n",
        "plt.suptitle('Histograms of Log-Transformed Numerical Columns')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-jmwwKfLGf0"
      },
      "source": [
        "\n",
        "- A log transformation is a mathematical operation applied to data where each data point is replaced by its logarithm (typically base 10 or natural log).\n",
        "\n",
        "- This transformation is particularly useful when dealing with data that spans several orders of magnitude or when the data distribution is highly skewed.\n",
        "\n",
        "- By applying a log transformation, large values are compressed, and small values are spread out, leading to a more symmetrical (or normal) distribution.\n",
        "\n",
        "- This can make patterns in the data more apparent and improve the performance of statistical models, especially those that assume normality or homoscedasticity (constant variance).\n",
        "\n",
        "- Log transformation is often necessary when dealing with positively skewed data, as it stabilizes variance and reduces the impact of outliers, making the data more suitable for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "npD3x7VpvgUc",
        "outputId": "39e2f7a2-db92-4fb0-b81d-0980a2f153b3"
      },
      "outputs": [],
      "source": [
        "# KDE plot for a specific column\n",
        "\"\"\"\n",
        "for column in df_log.columns:\n",
        "    sns.kdeplot(df[column], shade=True)\n",
        "    plt.title(f'KDE Plot for {column}')\n",
        "    plt.show()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cLQL8Ha5ltpi",
        "outputId": "92db421a-a71c-46e0-d8c4-cb78c6b6d41c"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# KDE plot for a specific column\n",
        "for column in df_log.columns:\n",
        "    sns.kdeplot(df_log[column], shade=True)\n",
        "    plt.title(f'KDE Plot for {column}')\n",
        "    plt.show()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzGGv7kOHO19"
      },
      "source": [
        "### Outliers amount changed after Log transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5PbEmhIHY2k",
        "outputId": "954d99c2-0467-402d-a1fe-0f435acac198"
      },
      "outputs": [],
      "source": [
        "# Calculate Q1 (25th percentile) and Q3 (75th percentile) for the original data\n",
        "Q1 = df[numerical_columns].quantile(0.25)\n",
        "Q3 = df[numerical_columns].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define outliers in the original data as points below Q1 - 1.5*IQR or above Q3 + 1.5*IQR\n",
        "outliers_original = ((df[numerical_columns] < (Q1 - 1.5 * IQR)) | (df[numerical_columns] > (Q3 + 1.5 * IQR)))\n",
        "\n",
        "# Count the number of outliers in each column for the original data\n",
        "outliers_count_original = outliers_original.sum()\n",
        "\n",
        "# Calculate Q1 (25th percentile) and Q3 (75th percentile) for the log-transformed data\n",
        "Q1_log = df_log[numerical_columns].quantile(0.25)\n",
        "Q3_log = df_log[numerical_columns].quantile(0.75)\n",
        "IQR_log = Q3_log - Q1_log\n",
        "\n",
        "# Define outliers in the log-transformed data\n",
        "outliers_log = ((df_log[numerical_columns] < (Q1_log - 1.5 * IQR_log)) | (df_log[numerical_columns] > (Q3_log + 1.5 * IQR_log)))\n",
        "\n",
        "# Count the number of outliers in each column for the log-transformed data\n",
        "outliers_count_log = outliers_log.sum()\n",
        "\n",
        "# Calculate the decrease in the number of outliers\n",
        "outliers_decrease = outliers_count_original - outliers_count_log\n",
        "\n",
        "# Display the results\n",
        "print(\"Number of Outliers in each column (Non-Log Transformed):\\n\", outliers_count_original)\n",
        "print(\"\\nNumber of Outliers in each column (Log-Transformed):\\n\", outliers_count_log)\n",
        "print(\"\\nDecrease in the number of outliers after log transformation:\\n\", outliers_decrease)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTHhAOIbHfkA"
      },
      "source": [
        "### Boxplot + Scatterplot before and after Log Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9EfhuQSeqKz0",
        "outputId": "af10befc-ead3-45f7-a351-2e88b83d20cf"
      },
      "outputs": [],
      "source": [
        "#Box plot\n",
        "df[numerical_columns].boxplot(figsize=(8, 6))\n",
        "plt.suptitle('Boxplots of Numerical Columns with Outliers')\n",
        "plt.show()\n",
        "\n",
        "df_log[numerical_columns].boxplot(figsize=(8, 6))\n",
        "plt.suptitle('Boxplots of Numerical Columns with Outliers (Log Transformed)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM26355VPEIx",
        "outputId": "8ebd8590-42d3-4634-a6d5-978e82539565"
      },
      "outputs": [],
      "source": [
        "#I'm not sure what happened but we have to make sure there is no null values again, if we delete this there's a bug\n",
        "# Fill missing values for numerical columns with mean\n",
        "df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].mean())\n",
        "\n",
        "print(df[numerical_columns].isna().sum())\n",
        "\n",
        "# Fill missing values for numerical columns with mean (Log Transformed)\n",
        "df_log[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].mean())\n",
        "\n",
        "print(df_log[numerical_columns].isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9_j1TCACyKL3",
        "outputId": "9ff107ee-5109-4773-bb0a-e7b415dccb59"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create a figure with subplots\n",
        "fig, axes = plt.subplots(3, 2, figsize=(15, 12))  # 3 rows, 2 columns layout\n",
        "fig.suptitle('Scatter Plots of Numerical Columns vs Popularity', fontsize=16)\n",
        "\n",
        "# Flatten the axes array for easy iteration\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Plot each scatter plot in a subplot\n",
        "for i, col in enumerate(numerical_columns):\n",
        "    if col != 'popularity':  # Skip 'popularity' as we are comparing against it\n",
        "        # Calculate correlation coefficient\n",
        "        corr_coef = np.corrcoef(df[col], df['popularity'])[0, 1]\n",
        "\n",
        "        # Fit linear regression model\n",
        "        X = df[col].values.reshape(-1, 1)\n",
        "        y = df['popularity'].values\n",
        "        model = LinearRegression().fit(X, y)\n",
        "        y_pred = model.predict(X)\n",
        "        r_squared = model.score(X, y)\n",
        "\n",
        "        # Plot scatter plot\n",
        "        sns.scatterplot(x=df[col], y=df['popularity'], ax=axes[i])\n",
        "        # Plot trend line\n",
        "        axes[i].plot(df[col], y_pred, color='red', linestyle='--')\n",
        "\n",
        "        # Annotate with correlation coefficient and R-squared\n",
        "        axes[i].text(0.05, 0.95, f'r={corr_coef:.2f}\\nR²={r_squared:.2f}',\n",
        "                     transform=axes[i].transAxes, fontsize=12,\n",
        "                     verticalalignment='top', bbox=dict(facecolor='white', alpha=0.7))\n",
        "\n",
        "        axes[i].set_title(f'{col} vs Popularity')\n",
        "        axes[i].set_xlabel(col)\n",
        "        axes[i].set_ylabel('popularity')\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wFifK20_zCIm",
        "outputId": "a61e413c-f664-4f94-e8aa-16521839a625"
      },
      "outputs": [],
      "source": [
        "#LOG TRANSFORMED VALUES\n",
        "numerical_columns = ['number_of_seasons', 'number_of_episodes', 'vote_count',\n",
        "                     'vote_average', 'popularity', 'episode_run_time']\n",
        "\n",
        "df_log = df[numerical_columns].apply(lambda x: np.log1p(x))\n",
        "\n",
        "# Create a figure with subplots\n",
        "fig, axes = plt.subplots(3, 2, figsize=(15, 12))  # 3 rows, 2 columns layout\n",
        "fig.suptitle('Scatter Plots of Numerical Columns vs Popularity (Log-transformed)', fontsize=16)\n",
        "\n",
        "# Flatten the axes array for easy iteration\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Plot each scatter plot in a subplot\n",
        "for i, col in enumerate(numerical_columns):\n",
        "    if col != 'popularity':  # Skip 'popularity' as we are comparing against it\n",
        "        # Calculate correlation coefficient\n",
        "        corr_coef = np.corrcoef(df_log[col], df_log['popularity'])[0, 1]\n",
        "\n",
        "        # Fit linear regression model\n",
        "        X = df_log[col].values.reshape(-1, 1)\n",
        "        y = df_log['popularity'].values\n",
        "        model = LinearRegression().fit(X, y)\n",
        "        y_pred = model.predict(X)\n",
        "        r_squared = model.score(X, y)\n",
        "\n",
        "        # Plot scatter plot\n",
        "        sns.scatterplot(x=df_log[col], y=df_log['popularity'], ax=axes[i])\n",
        "        # Plot trend line\n",
        "        axes[i].plot(df_log[col], y_pred, color='red', linestyle='--')\n",
        "\n",
        "        # Annotate with correlation coefficient and R-squared\n",
        "        axes[i].text(0.05, 0.95, f'r={corr_coef:.2f}\\nR²={r_squared:.2f}',\n",
        "                     transform=axes[i].transAxes, fontsize=12,\n",
        "                     verticalalignment='top', bbox=dict(facecolor='white', alpha=0.7))\n",
        "\n",
        "        axes[i].set_title(f'{col} vs Popularity (Log-transformed)')\n",
        "        axes[i].set_xlabel(col)\n",
        "        axes[i].set_ylabel('popularity')\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpVKWS6HJaYj"
      },
      "source": [
        "## Winsorize Outliers (after Log transformation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otDJ_lqBKjeM",
        "outputId": "8c257bd4-027b-4f9e-f0ae-79f0a2042716"
      },
      "outputs": [],
      "source": [
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "# Define the limits for Winsorization\n",
        "lower_limit = 0.05  # 5th percentile\n",
        "upper_limit = 0.95  # 95th percentile\n",
        "\n",
        "# Apply Winsorization to each numerical column\n",
        "df_winsorized = df_log[numerical_columns].apply(lambda x: winsorize(x, limits=(lower_limit, 1 - upper_limit)))\n",
        "\n",
        "# Display the first few rows of the winsorized data\n",
        "print(df_winsorized.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lgpVcs6nKqwD",
        "outputId": "0b5ad995-19f5-4a4a-d8e2-2bb2eede6a8b"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot histograms for each column in the winsorized DataFrame\n",
        "for column in df_winsorized.columns:\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.histplot(df_winsorized[column], kde=True)\n",
        "    plt.title(f'Distribution of {column} after Winsorization')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDB5lODjpDrn"
      },
      "source": [
        "# Normalization of Numerical Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "4hRlUlTspCEx",
        "outputId": "a9741ccd-fdda-4a99-cf50-a7112e3fe6fd"
      },
      "outputs": [],
      "source": [
        "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em1IuRuYGpLK"
      },
      "source": [
        "# Hypothesis: Predicting Popularity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "kqG4JEgMF8an",
        "outputId": "484a6232-63ce-4e0f-9c34-2f943870b434"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "top_100_df = df.sort_values(by='popularity', ascending=False).head(100)\n",
        "top_100_df_cleaned = top_100_df[top_100_df['cleaned_overview'].notna()]\n",
        "\n",
        "text = ' '.join(top_100_df_cleaned['cleaned_overview'].astype(str))\n",
        "\n",
        "STOPWORDS = []\n",
        "custom_stopwords = set(STOPWORDS)\n",
        "custom_stopwords.update([\n",
        "    'show', 'series', 'television', 'episode', 'television series',\n",
        "    'and', 'is', 'a', 'of', 'the', 'to', 'from', 'as', 'in', 'with', 'it', 'was', 'her', 'she', 'his', 'has', 'by', 'on', 'at', 'he', 'that',\n",
        "    'an', 'who', 'its', 'after', 'program'\n",
        "])\n",
        "\n",
        "# Generate the word cloud for the top 50 shows\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='viridis',\n",
        "                      max_words=200, stopwords=custom_stopwords).generate(text)\n",
        "\n",
        "# Plot the word cloud\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud for Overviews of Top 100 Most Popular TV Shows (Filtered)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating our labeled examples with 'y' as our label and 'X' being our features\n",
        "y = df['popularity']\n",
        "X = df.drop(columns = 'popularity', axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use train_test_split() because we want to split our data into training and test sets.\n",
        "\n",
        "Train tests are used for fitting the model which means we train our model with this dataset.\n",
        "\n",
        "Test sets are used to accurately evalute our final model's predicitions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating the training and test sets out of the labeled examples\n",
        "# 30% of our data is for the test size, this will be the data used to test the model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#• DISCLAIMER: Will indicate an error until we drop categorical columns\n",
        "LR_model = LinearRegression()\n",
        "LR_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_lr_pred = LR_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute the RMSE using mean_squared_error()\n",
        "LR_rmse = mean_squared_error(y_test, y_lr_pred, squared = False)\n",
        "\n",
        "# Compute the R2 score using r2_score()\n",
        "LR_r2 = r2_score(y_test, y_lr_pred)\n",
        "\n",
        "print('Linear Regression: Root Mean Squared Error: '.format(LR_rmse))\n",
        "print('[Linear Regression: R^2: '.format(LR_r2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}