{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awKwXW-ym0nL"
      },
      "source": [
        "# Data Understanding\n",
        "\n",
        "### 1. Building the Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "lykkNTgYRSD4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypag8qnklenf"
      },
      "source": [
        "Insert TMDB_tv_dataset_v3.csv to the files section of the Google Colab for access."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "3Tv7h8xXlR9A"
      },
      "outputs": [],
      "source": [
        "TMDB_filename = os.path.join(os.getcwd(), \"TMDB_tv_dataset_v3.csv\")\n",
        "df = pd.read_csv(TMDB_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv8rNAlTnAbE"
      },
      "source": [
        "### 2. Basic Exploration of TMDB Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KN125jOYnIND",
        "outputId": "e35f50a5-d147-4baa-b45c-5dd901d1dfb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(168639, 29)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#dataframe shape\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "GuDZCtVnnY4q",
        "outputId": "08c9d9dd-929c-4d23-da54-520605549efe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>number_of_seasons</th>\n",
              "      <th>number_of_episodes</th>\n",
              "      <th>original_language</th>\n",
              "      <th>vote_count</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>overview</th>\n",
              "      <th>adult</th>\n",
              "      <th>backdrop_path</th>\n",
              "      <th>...</th>\n",
              "      <th>tagline</th>\n",
              "      <th>genres</th>\n",
              "      <th>created_by</th>\n",
              "      <th>languages</th>\n",
              "      <th>networks</th>\n",
              "      <th>origin_country</th>\n",
              "      <th>spoken_languages</th>\n",
              "      <th>production_companies</th>\n",
              "      <th>production_countries</th>\n",
              "      <th>episode_run_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1399</td>\n",
              "      <td>Game of Thrones</td>\n",
              "      <td>8</td>\n",
              "      <td>73</td>\n",
              "      <td>en</td>\n",
              "      <td>21857</td>\n",
              "      <td>8.442</td>\n",
              "      <td>Seven noble families fight for control of the ...</td>\n",
              "      <td>False</td>\n",
              "      <td>/2OMB0ynKlyIenMJWI2Dy9IWT4c.jpg</td>\n",
              "      <td>...</td>\n",
              "      <td>Winter Is Coming</td>\n",
              "      <td>Sci-Fi &amp; Fantasy, Drama, Action &amp; Adventure</td>\n",
              "      <td>David Benioff, D.B. Weiss</td>\n",
              "      <td>en</td>\n",
              "      <td>HBO</td>\n",
              "      <td>US</td>\n",
              "      <td>English</td>\n",
              "      <td>Revolution Sun Studios, Television 360, Genera...</td>\n",
              "      <td>United Kingdom, United States of America</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>71446</td>\n",
              "      <td>Money Heist</td>\n",
              "      <td>3</td>\n",
              "      <td>41</td>\n",
              "      <td>es</td>\n",
              "      <td>17836</td>\n",
              "      <td>8.257</td>\n",
              "      <td>To carry out the biggest heist in history, a m...</td>\n",
              "      <td>False</td>\n",
              "      <td>/gFZriCkpJYsApPZEF3jhxL4yLzG.jpg</td>\n",
              "      <td>...</td>\n",
              "      <td>The perfect robbery.</td>\n",
              "      <td>Crime, Drama</td>\n",
              "      <td>Álex Pina</td>\n",
              "      <td>es</td>\n",
              "      <td>Netflix, Antena 3</td>\n",
              "      <td>ES</td>\n",
              "      <td>Español</td>\n",
              "      <td>Vancouver Media</td>\n",
              "      <td>Spain</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>66732</td>\n",
              "      <td>Stranger Things</td>\n",
              "      <td>4</td>\n",
              "      <td>34</td>\n",
              "      <td>en</td>\n",
              "      <td>16161</td>\n",
              "      <td>8.624</td>\n",
              "      <td>When a young boy vanishes, a small town uncove...</td>\n",
              "      <td>False</td>\n",
              "      <td>/2MaumbgBlW1NoPo3ZJO38A6v7OS.jpg</td>\n",
              "      <td>...</td>\n",
              "      <td>Every ending has a beginning.</td>\n",
              "      <td>Drama, Sci-Fi &amp; Fantasy, Mystery</td>\n",
              "      <td>Matt Duffer, Ross Duffer</td>\n",
              "      <td>en</td>\n",
              "      <td>Netflix</td>\n",
              "      <td>US</td>\n",
              "      <td>English</td>\n",
              "      <td>21 Laps Entertainment, Monkey Massacre Product...</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1402</td>\n",
              "      <td>The Walking Dead</td>\n",
              "      <td>11</td>\n",
              "      <td>177</td>\n",
              "      <td>en</td>\n",
              "      <td>15432</td>\n",
              "      <td>8.121</td>\n",
              "      <td>Sheriff's deputy Rick Grimes awakens from a co...</td>\n",
              "      <td>False</td>\n",
              "      <td>/x4salpjB11umlUOltfNvSSrjSXm.jpg</td>\n",
              "      <td>...</td>\n",
              "      <td>Fight the dead. Fear the living.</td>\n",
              "      <td>Action &amp; Adventure, Drama, Sci-Fi &amp; Fantasy</td>\n",
              "      <td>Frank Darabont</td>\n",
              "      <td>en</td>\n",
              "      <td>AMC</td>\n",
              "      <td>US</td>\n",
              "      <td>English</td>\n",
              "      <td>AMC Studios, Circle of Confusion, Valhalla Mot...</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63174</td>\n",
              "      <td>Lucifer</td>\n",
              "      <td>6</td>\n",
              "      <td>93</td>\n",
              "      <td>en</td>\n",
              "      <td>13870</td>\n",
              "      <td>8.486</td>\n",
              "      <td>Bored and unhappy as the Lord of Hell, Lucifer...</td>\n",
              "      <td>False</td>\n",
              "      <td>/aDBRtunw49UF4XmqfyNuD9nlYIu.jpg</td>\n",
              "      <td>...</td>\n",
              "      <td>It's good to be bad.</td>\n",
              "      <td>Crime, Sci-Fi &amp; Fantasy</td>\n",
              "      <td>Tom Kapinos</td>\n",
              "      <td>en</td>\n",
              "      <td>FOX, Netflix</td>\n",
              "      <td>US</td>\n",
              "      <td>English</td>\n",
              "      <td>Warner Bros. Television, DC Entertainment, Jer...</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      id              name  number_of_seasons  number_of_episodes  \\\n",
              "0   1399   Game of Thrones                  8                  73   \n",
              "1  71446       Money Heist                  3                  41   \n",
              "2  66732   Stranger Things                  4                  34   \n",
              "3   1402  The Walking Dead                 11                 177   \n",
              "4  63174           Lucifer                  6                  93   \n",
              "\n",
              "  original_language  vote_count  vote_average  \\\n",
              "0                en       21857         8.442   \n",
              "1                es       17836         8.257   \n",
              "2                en       16161         8.624   \n",
              "3                en       15432         8.121   \n",
              "4                en       13870         8.486   \n",
              "\n",
              "                                            overview  adult  \\\n",
              "0  Seven noble families fight for control of the ...  False   \n",
              "1  To carry out the biggest heist in history, a m...  False   \n",
              "2  When a young boy vanishes, a small town uncove...  False   \n",
              "3  Sheriff's deputy Rick Grimes awakens from a co...  False   \n",
              "4  Bored and unhappy as the Lord of Hell, Lucifer...  False   \n",
              "\n",
              "                      backdrop_path  ...                           tagline  \\\n",
              "0   /2OMB0ynKlyIenMJWI2Dy9IWT4c.jpg  ...                  Winter Is Coming   \n",
              "1  /gFZriCkpJYsApPZEF3jhxL4yLzG.jpg  ...              The perfect robbery.   \n",
              "2  /2MaumbgBlW1NoPo3ZJO38A6v7OS.jpg  ...     Every ending has a beginning.   \n",
              "3  /x4salpjB11umlUOltfNvSSrjSXm.jpg  ...  Fight the dead. Fear the living.   \n",
              "4  /aDBRtunw49UF4XmqfyNuD9nlYIu.jpg  ...              It's good to be bad.   \n",
              "\n",
              "                                        genres                 created_by  \\\n",
              "0  Sci-Fi & Fantasy, Drama, Action & Adventure  David Benioff, D.B. Weiss   \n",
              "1                                 Crime, Drama                  Álex Pina   \n",
              "2             Drama, Sci-Fi & Fantasy, Mystery   Matt Duffer, Ross Duffer   \n",
              "3  Action & Adventure, Drama, Sci-Fi & Fantasy             Frank Darabont   \n",
              "4                      Crime, Sci-Fi & Fantasy                Tom Kapinos   \n",
              "\n",
              "   languages           networks  origin_country spoken_languages  \\\n",
              "0         en                HBO              US          English   \n",
              "1         es  Netflix, Antena 3              ES          Español   \n",
              "2         en            Netflix              US          English   \n",
              "3         en                AMC              US          English   \n",
              "4         en       FOX, Netflix              US          English   \n",
              "\n",
              "                                production_companies  \\\n",
              "0  Revolution Sun Studios, Television 360, Genera...   \n",
              "1                                    Vancouver Media   \n",
              "2  21 Laps Entertainment, Monkey Massacre Product...   \n",
              "3  AMC Studios, Circle of Confusion, Valhalla Mot...   \n",
              "4  Warner Bros. Television, DC Entertainment, Jer...   \n",
              "\n",
              "                       production_countries episode_run_time  \n",
              "0  United Kingdom, United States of America                0  \n",
              "1                                     Spain               70  \n",
              "2                  United States of America                0  \n",
              "3                  United States of America               42  \n",
              "4                  United States of America               45  \n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#first few rows:\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "2_76pTosnbcx",
        "outputId": "2c4f411a-d002-4cb0-a9fe-79f3c027b7e9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>number_of_seasons</th>\n",
              "      <th>number_of_episodes</th>\n",
              "      <th>original_language</th>\n",
              "      <th>vote_count</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>overview</th>\n",
              "      <th>adult</th>\n",
              "      <th>backdrop_path</th>\n",
              "      <th>...</th>\n",
              "      <th>tagline</th>\n",
              "      <th>genres</th>\n",
              "      <th>created_by</th>\n",
              "      <th>languages</th>\n",
              "      <th>networks</th>\n",
              "      <th>origin_country</th>\n",
              "      <th>spoken_languages</th>\n",
              "      <th>production_companies</th>\n",
              "      <th>production_countries</th>\n",
              "      <th>episode_run_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>168634</th>\n",
              "      <td>239099</td>\n",
              "      <td>母乳酱想要喷出来</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>zh</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168635</th>\n",
              "      <td>241205</td>\n",
              "      <td>Barbie Dream Squad</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>es</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dee Shipley, Blair Davidson</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>US</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168636</th>\n",
              "      <td>240696</td>\n",
              "      <td>Picasso</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>bn</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Murder, art and a journalist's relentless ques...</td>\n",
              "      <td>False</td>\n",
              "      <td>/fseBBbvHtdcZS5M7bSjOxYsVe5.jpg</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Crime</td>\n",
              "      <td>NaN</td>\n",
              "      <td>bn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IN</td>\n",
              "      <td>বাংলা</td>\n",
              "      <td>NaN</td>\n",
              "      <td>India</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168637</th>\n",
              "      <td>240697</td>\n",
              "      <td>女子大生危険なアルバイト</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>A college student gets into trouble when she m...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>US</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168638</th>\n",
              "      <td>237566</td>\n",
              "      <td>Welcome to My World</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Short-lives series on Youtube Red.</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Paul Vandervort</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>US</td>\n",
              "      <td>NaN</td>\n",
              "      <td>YouTube Red</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id                 name  number_of_seasons  number_of_episodes  \\\n",
              "168634  239099             母乳酱想要喷出来                  1                   1   \n",
              "168635  241205   Barbie Dream Squad                  1                   1   \n",
              "168636  240696              Picasso                  1                   1   \n",
              "168637  240697         女子大生危険なアルバイト                  1                   1   \n",
              "168638  237566  Welcome to My World                  1                   5   \n",
              "\n",
              "       original_language  vote_count  vote_average  \\\n",
              "168634                zh           0           0.0   \n",
              "168635                es           0           0.0   \n",
              "168636                bn           0           0.0   \n",
              "168637                en           0           0.0   \n",
              "168638                en           0           0.0   \n",
              "\n",
              "                                                 overview  adult  \\\n",
              "168634                                                NaN  False   \n",
              "168635                                                NaN  False   \n",
              "168636  Murder, art and a journalist's relentless ques...  False   \n",
              "168637  A college student gets into trouble when she m...  False   \n",
              "168638                 Short-lives series on Youtube Red.  False   \n",
              "\n",
              "                          backdrop_path  ... tagline genres  \\\n",
              "168634                              NaN  ...     NaN    NaN   \n",
              "168635                              NaN  ...     NaN    NaN   \n",
              "168636  /fseBBbvHtdcZS5M7bSjOxYsVe5.jpg  ...     NaN  Crime   \n",
              "168637                              NaN  ...     NaN    NaN   \n",
              "168638                              NaN  ...     NaN    NaN   \n",
              "\n",
              "                         created_by  languages networks  origin_country  \\\n",
              "168634                          NaN        NaN      NaN              CN   \n",
              "168635  Dee Shipley, Blair Davidson        NaN      NaN              US   \n",
              "168636                          NaN         bn      NaN              IN   \n",
              "168637                          NaN        NaN      NaN              US   \n",
              "168638              Paul Vandervort        NaN      NaN              US   \n",
              "\n",
              "       spoken_languages production_companies      production_countries  \\\n",
              "168634              NaN                  NaN                       NaN   \n",
              "168635              NaN                  NaN                       NaN   \n",
              "168636            বাংলা                  NaN                     India   \n",
              "168637              NaN                  NaN                       NaN   \n",
              "168638              NaN          YouTube Red  United States of America   \n",
              "\n",
              "       episode_run_time  \n",
              "168634                0  \n",
              "168635                0  \n",
              "168636                0  \n",
              "168637                0  \n",
              "168638                0  \n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#last few rows:\n",
        "display(df.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "9biV4VGYnfYC",
        "outputId": "457f8e57-85e3-486d-ad11-4002ca984523"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>number_of_seasons</th>\n",
              "      <th>number_of_episodes</th>\n",
              "      <th>vote_count</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>popularity</th>\n",
              "      <th>episode_run_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>168639.000000</td>\n",
              "      <td>168639.000000</td>\n",
              "      <td>168639.000000</td>\n",
              "      <td>168639.000000</td>\n",
              "      <td>168639.000000</td>\n",
              "      <td>168639.000000</td>\n",
              "      <td>168639.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>111307.074704</td>\n",
              "      <td>1.548497</td>\n",
              "      <td>24.465082</td>\n",
              "      <td>13.305054</td>\n",
              "      <td>2.333843</td>\n",
              "      <td>5.882644</td>\n",
              "      <td>22.603348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>76451.662352</td>\n",
              "      <td>2.942872</td>\n",
              "      <td>134.799622</td>\n",
              "      <td>190.809059</td>\n",
              "      <td>3.454334</td>\n",
              "      <td>42.023216</td>\n",
              "      <td>47.950427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>45936.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>97734.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.857000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>196923.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.431500</td>\n",
              "      <td>42.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>251213.000000</td>\n",
              "      <td>240.000000</td>\n",
              "      <td>20839.000000</td>\n",
              "      <td>21857.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3707.008000</td>\n",
              "      <td>6032.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id  number_of_seasons  number_of_episodes     vote_count  \\\n",
              "count  168639.000000      168639.000000       168639.000000  168639.000000   \n",
              "mean   111307.074704           1.548497           24.465082      13.305054   \n",
              "std     76451.662352           2.942872          134.799622     190.809059   \n",
              "min         1.000000           0.000000            0.000000       0.000000   \n",
              "25%     45936.500000           1.000000            1.000000       0.000000   \n",
              "50%     97734.000000           1.000000            6.000000       0.000000   \n",
              "75%    196923.500000           1.000000           20.000000       1.000000   \n",
              "max    251213.000000         240.000000        20839.000000   21857.000000   \n",
              "\n",
              "        vote_average     popularity  episode_run_time  \n",
              "count  168639.000000  168639.000000     168639.000000  \n",
              "mean        2.333843       5.882644         22.603348  \n",
              "std         3.454334      42.023216         47.950427  \n",
              "min         0.000000       0.000000          0.000000  \n",
              "25%         0.000000       0.600000          0.000000  \n",
              "50%         0.000000       0.857000          0.000000  \n",
              "75%         6.000000       2.431500         42.000000  \n",
              "max        10.000000    3707.008000       6032.000000  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# display basic statistics of numeric columns\n",
        "display(df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "ml3zvEoFniuF",
        "outputId": "2d4268b3-5494-4000-cdba-c359d4b37673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 168639 entries, 0 to 168638\n",
            "Data columns (total 29 columns):\n",
            " #   Column                Non-Null Count   Dtype  \n",
            "---  ------                --------------   -----  \n",
            " 0   id                    168639 non-null  int64  \n",
            " 1   name                  168634 non-null  object \n",
            " 2   number_of_seasons     168639 non-null  int64  \n",
            " 3   number_of_episodes    168639 non-null  int64  \n",
            " 4   original_language     168639 non-null  object \n",
            " 5   vote_count            168639 non-null  int64  \n",
            " 6   vote_average          168639 non-null  float64\n",
            " 7   overview              93333 non-null   object \n",
            " 8   adult                 168639 non-null  bool   \n",
            " 9   backdrop_path         77780 non-null   object \n",
            " 10  first_air_date        136903 non-null  object \n",
            " 11  last_air_date         138735 non-null  object \n",
            " 12  homepage              50998 non-null   object \n",
            " 13  in_production         168639 non-null  bool   \n",
            " 14  original_name         168634 non-null  object \n",
            " 15  popularity            168639 non-null  float64\n",
            " 16  poster_path           108737 non-null  object \n",
            " 17  type                  168639 non-null  object \n",
            " 18  status                168639 non-null  object \n",
            " 19  tagline               5330 non-null    object \n",
            " 20  genres                99713 non-null   object \n",
            " 21  created_by            36496 non-null   object \n",
            " 22  languages             110050 non-null  object \n",
            " 23  networks              97589 non-null   object \n",
            " 24  origin_country        137609 non-null  object \n",
            " 25  spoken_languages      109280 non-null  object \n",
            " 26  production_companies  59342 non-null   object \n",
            " 27  production_countries  77511 non-null   object \n",
            " 28  episode_run_time      168639 non-null  int64  \n",
            "dtypes: bool(2), float64(2), int64(5), object(20)\n",
            "memory usage: 35.1+ MB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# display info about DataFrame\n",
        "display(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGK3CW2LnlEq",
        "outputId": "756173ed-ce71-4e08-95a8-46497aaadd66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['id',\n",
              " 'name',\n",
              " 'number_of_seasons',\n",
              " 'number_of_episodes',\n",
              " 'original_language',\n",
              " 'vote_count',\n",
              " 'vote_average',\n",
              " 'overview',\n",
              " 'adult',\n",
              " 'backdrop_path',\n",
              " 'first_air_date',\n",
              " 'last_air_date',\n",
              " 'homepage',\n",
              " 'in_production',\n",
              " 'original_name',\n",
              " 'popularity',\n",
              " 'poster_path',\n",
              " 'type',\n",
              " 'status',\n",
              " 'tagline',\n",
              " 'genres',\n",
              " 'created_by',\n",
              " 'languages',\n",
              " 'networks',\n",
              " 'origin_country',\n",
              " 'spoken_languages',\n",
              " 'production_companies',\n",
              " 'production_countries',\n",
              " 'episode_run_time']"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#identifying features\n",
        "df.columns.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMHO36bQntgL"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By72rPZ_n0Zl"
      },
      "source": [
        "### Handle Missing Values  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-enK6ionv7t",
        "outputId": "dc12c115-52b6-42e1-eedf-4a15ad16ed15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 168639 entries, 0 to 168638\n",
            "Data columns (total 29 columns):\n",
            " #   Column                Non-Null Count   Dtype  \n",
            "---  ------                --------------   -----  \n",
            " 0   id                    168639 non-null  int64  \n",
            " 1   name                  168634 non-null  object \n",
            " 2   number_of_seasons     168639 non-null  int64  \n",
            " 3   number_of_episodes    168639 non-null  int64  \n",
            " 4   original_language     168639 non-null  object \n",
            " 5   vote_count            168639 non-null  int64  \n",
            " 6   vote_average          168639 non-null  float64\n",
            " 7   overview              93333 non-null   object \n",
            " 8   adult                 168639 non-null  bool   \n",
            " 9   backdrop_path         77780 non-null   object \n",
            " 10  first_air_date        136903 non-null  object \n",
            " 11  last_air_date         138735 non-null  object \n",
            " 12  homepage              50998 non-null   object \n",
            " 13  in_production         168639 non-null  bool   \n",
            " 14  original_name         168634 non-null  object \n",
            " 15  popularity            168639 non-null  float64\n",
            " 16  poster_path           108737 non-null  object \n",
            " 17  type                  168639 non-null  object \n",
            " 18  status                168639 non-null  object \n",
            " 19  tagline               5330 non-null    object \n",
            " 20  genres                99713 non-null   object \n",
            " 21  created_by            36496 non-null   object \n",
            " 22  languages             110050 non-null  object \n",
            " 23  networks              97589 non-null   object \n",
            " 24  origin_country        137609 non-null  object \n",
            " 25  spoken_languages      109280 non-null  object \n",
            " 26  production_companies  59342 non-null   object \n",
            " 27  production_countries  77511 non-null   object \n",
            " 28  episode_run_time      168639 non-null  int64  \n",
            "dtypes: bool(2), float64(2), int64(5), object(20)\n",
            "memory usage: 35.1+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Inspect the structure of the data\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoPxeURXrUCQ",
        "outputId": "9b53e5e1-41c9-4fce-8a89-41dbbafd305f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id                           0\n",
            "name                         5\n",
            "number_of_seasons            0\n",
            "number_of_episodes           0\n",
            "original_language            0\n",
            "vote_count                   0\n",
            "vote_average                 0\n",
            "overview                 75306\n",
            "adult                        0\n",
            "backdrop_path            90859\n",
            "first_air_date           31736\n",
            "last_air_date            29904\n",
            "homepage                117641\n",
            "in_production                0\n",
            "original_name                5\n",
            "popularity                   0\n",
            "poster_path              59902\n",
            "type                         0\n",
            "status                       0\n",
            "tagline                 163309\n",
            "genres                   68926\n",
            "created_by              132143\n",
            "languages                58589\n",
            "networks                 71050\n",
            "origin_country           31030\n",
            "spoken_languages         59359\n",
            "production_companies    109297\n",
            "production_countries     91128\n",
            "episode_run_time             0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BTc6HuVrVbT",
        "outputId": "f0f247e8-ff9e-4593-a8a4-a3cadf4ea2c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id                        int64\n",
            "name                     object\n",
            "number_of_seasons         int64\n",
            "number_of_episodes        int64\n",
            "original_language        object\n",
            "vote_count                int64\n",
            "vote_average            float64\n",
            "overview                 object\n",
            "adult                      bool\n",
            "backdrop_path            object\n",
            "first_air_date           object\n",
            "last_air_date            object\n",
            "homepage                 object\n",
            "in_production              bool\n",
            "original_name            object\n",
            "popularity              float64\n",
            "poster_path              object\n",
            "type                     object\n",
            "status                   object\n",
            "tagline                  object\n",
            "genres                   object\n",
            "created_by               object\n",
            "languages                object\n",
            "networks                 object\n",
            "origin_country           object\n",
            "spoken_languages         object\n",
            "production_companies     object\n",
            "production_countries     object\n",
            "episode_run_time          int64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Verify the data types of all columns\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "dFulnP3LrbmV"
      },
      "outputs": [],
      "source": [
        "# Fill missing values for numerical columns with mean\n",
        "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "xqq4xjWwrd3p"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "the changes I made here are that I filter out the 'object' data types and then check to see if it is not the \n",
        "'genres' column. if it is not, then I add it to the 'columns_to_fill\" list. this is because I am labeling\n",
        "shows without a genre as 'Unknown' in the one-hot encoding step. then after that, I apply the mode of the \n",
        "specific column to the missing value for now. \n",
        "'''\n",
        "\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "columns_to_fill = [col for col in categorical_cols if col != 'genres']\n",
        "df[columns_to_fill] = df[columns_to_fill].apply(lambda col: col.fillna(col.mode()[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw9IKmG6rgdl",
        "outputId": "6278f46b-8103-47d4-feac-3319578a6c65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id                          0\n",
            "name                        0\n",
            "number_of_seasons           0\n",
            "number_of_episodes          0\n",
            "original_language           0\n",
            "vote_count                  0\n",
            "vote_average                0\n",
            "overview                    0\n",
            "adult                       0\n",
            "backdrop_path               0\n",
            "first_air_date              0\n",
            "last_air_date               0\n",
            "homepage                    0\n",
            "in_production               0\n",
            "original_name               0\n",
            "popularity                  0\n",
            "poster_path                 0\n",
            "type                        0\n",
            "status                      0\n",
            "tagline                     0\n",
            "genres                  68926\n",
            "created_by                  0\n",
            "languages                   0\n",
            "networks                    0\n",
            "origin_country              0\n",
            "spoken_languages            0\n",
            "production_companies        0\n",
            "production_countries        0\n",
            "episode_run_time            0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Verify that there are no missing values\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Yn2zh6tn2nj"
      },
      "source": [
        "### Remove Duplicates  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srKmlG3N0ywy"
      },
      "source": [
        "1,580 rows of data were removed due to it being a duplicate row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuEC5Gnz1UWb",
        "outputId": "6be992d4-adef-4a7d-8708-0ed40a392694"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of duplicate rows: 1580\n"
          ]
        }
      ],
      "source": [
        "# Check how many duplicates are there\n",
        "num_duplicate_rows = df.duplicated().sum()\n",
        "print(f\"Number of duplicate rows: {num_duplicate_rows}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "FPIWTsdW1fhU"
      },
      "outputs": [],
      "source": [
        "# Remove duplicates\n",
        "df = df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPXqO7Ww1jE9",
        "outputId": "5d9a74b0-b259-4d3a-8032-a722ccc1d21c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of duplicates after removing: 0\n"
          ]
        }
      ],
      "source": [
        "num_duplicates_after = df.duplicated().sum()\n",
        "print(f\"Number of duplicates after removing: {num_duplicates_after}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JFbKwEGn5NJ"
      },
      "source": [
        "### Clean Text Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "IectzYdJn8wO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\nI made some notes on how to get nltk to work on your enviroment, I know that this has worked on VS Code \\non macOS so if that is the enviroment and OS that you are using this should work. I hope it helps!\\n\\nhow to install nltk:\\n1. make sure you are working in a virtual enviroment when working on vs code, also\\nensure you have python installed with the following command:\\npython --version\\n\\n2. on macos, run this command to create the virtual enviroment:\\npython3 -m venv myenv\\n\\n3. then activate the virtual enviroment with this command:\\nsource myenv/bin/activate\\n\\n4. then you can install packages like nltk with this command:\\npip install nltk\\n\\n5. once you have done this, check to see if nltk have been dowloaded with this command:\\npip list\\nnltk should show up in the list\\n\\n6. then in the terminal type in 'python3', then 'import nltk', then nltk.__version__, this will help\\nensure that nltk is installed\\n\\n7. then I ensured I have actually activated the virtual enviroment with this command, this\\nwill be different depending on which directory your enviroment is located:\\nsource /Users/safiaboutaleb/Developer/directv_tvrec/myenv/bin/activate\\n\\n8. then I tried to reinstall the certificates with this command for nltk to finally work:\\n/Applications/Python\\\\ 3.11/Install\\\\ Certificates.command\\n\\nThe following lines of code below here are needed to install the nessesary components of nltk,\\nonce you run this once, you can delete these lines of code because they will have already been installed:\\n\\nnltk.download('punkt')\\nnltk.download('stopwords')\\nnltk.download('wordnet')\\n\\nyt video that helped a bit:\\nhttps://www.youtube.com/watch?v=85Xr0UGR8qQ\\n\""
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "I made some notes on how to get nltk to work on your enviroment, I know that this has worked on VS Code \n",
        "on macOS so if that is the enviroment and OS that you are using this should work. I hope it helps!\n",
        "\n",
        "how to install nltk:\n",
        "1. make sure you are working in a virtual enviroment when working on vs code, also\n",
        "ensure you have python installed with the following command:\n",
        "python --version\n",
        "\n",
        "2. on macos, run this command to create the virtual enviroment:\n",
        "python3 -m venv myenv\n",
        "\n",
        "3. then activate the virtual enviroment with this command:\n",
        "source myenv/bin/activate\n",
        "\n",
        "4. then you can install packages like nltk with this command:\n",
        "pip install nltk\n",
        "\n",
        "5. once you have done this, check to see if nltk have been dowloaded with this command:\n",
        "pip list\n",
        "nltk should show up in the list\n",
        "\n",
        "6. then in the terminal type in 'python3', then 'import nltk', then nltk.__version__, this will help\n",
        "ensure that nltk is installed\n",
        "\n",
        "7. then I ensured I have actually activated the virtual enviroment with this command, this\n",
        "will be different depending on which directory your enviroment is located:\n",
        "source /Users/safiaboutaleb/Developer/directv_tvrec/myenv/bin/activate\n",
        "\n",
        "8. then I tried to reinstall the certificates with this command for nltk to finally work:\n",
        "/Applications/Python\\ 3.11/Install\\ Certificates.command\n",
        "\n",
        "The following lines of code below here are needed to install the nessesary components of nltk,\n",
        "once you run this once, you can delete these lines of code because they will have already been installed:\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "yt video that helped a bit:\n",
        "https://www.youtube.com/watch?v=85Xr0UGR8qQ\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "clean text function to convert text to lowercase, remove special characters \n",
        "(punctuation, numbers, etc.), remove stop words, tokenize, and apply lemmatization\n",
        "'''\n",
        "\n",
        "def clean_text(text):\n",
        "  text = text.lower()\n",
        "    \n",
        "  text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    \n",
        "  tokens = word_tokenize(text)\n",
        "    \n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tokens = [word for word in tokens if word not in stop_words]\n",
        "    \n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    \n",
        "  cleaned_text = ' '.join(tokens)\n",
        "    \n",
        "  return cleaned_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "now we use the clean_text function on the overview column\n",
        "'''\n",
        "\n",
        "df['cleaned_overview'] = df['overview'].apply(lambda x: clean_text(x) if pd.notnull(x) else '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "seven noble family fight control mythical land westeros friction house lead fullscale war ancient evil awakens farthest north amidst war neglected military order misfit night watch stand realm men icy horror beyond\n",
            "Seven noble families fight for control of the mythical land of Westeros. Friction between the houses leads to full-scale war. All while a very ancient evil awakens in the farthest north. Amidst the war, a neglected military order of misfits, the Night's Watch, is all that stands between the realms of men and icy horrors beyond.\n"
          ]
        }
      ],
      "source": [
        "print(df['cleaned_overview'][0])\n",
        "print(df['overview'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.drop('overview', axis=1) # drop the original 'overview' column and save the chagnes to the csv file\n",
        "df.to_csv('TMDB_tv_dataset_v3.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg6J8Ztun-la"
      },
      "source": [
        "### Normalize/Standardize Numeric Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCqwjakYn-PD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFYHa_HYoBM3"
      },
      "source": [
        "### One-Hot Encoding of Categorical Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Genre One-Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "my plan here is to just split each genre as a token by using the comma as a delimiter, then find all\n",
        "of the unique genres, and then one-hot encode them so I can drop the original genres column\n",
        "'''\n",
        "\n",
        "df['genres'] = df['genres'].fillna('Unknown') # for genres that are empty just call them Unknown\n",
        "\n",
        "df['genres'] = df['genres'].apply(lambda x: x.split(', '))\n",
        "\n",
        "unique_genres = sorted(set(genre for genres in df['genres'] for genre in genres))\n",
        "\n",
        "for genre in unique_genres:\n",
        "  df[genre] = df['genres'].apply(lambda genres: int(genre in genres))\n",
        "\n",
        "df = df.drop('genres', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [],
      "source": [
        "# now here I can save the modifications to the csv file\n",
        "df.to_csv('TMDB_tv_dataset_v3.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Rest of the One-Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "B5c1ZRr0oDaS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name                    155586\n",
            "original_language          106\n",
            "backdrop_path            76300\n",
            "first_air_date           18286\n",
            "last_air_date            18705\n",
            "homepage                 49758\n",
            "original_name           157313\n",
            "poster_path             106050\n",
            "type                         7\n",
            "status                       6\n",
            "tagline                   5267\n",
            "created_by               26081\n",
            "languages                 1113\n",
            "networks                  8196\n",
            "origin_country             792\n",
            "spoken_languages           946\n",
            "production_companies     27132\n",
            "production_countries      1247\n",
            "cleaned_overview         91026\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Creating a list of all columns with object values and inspecting their unique values\n",
        "list = df.select_dtypes(include=['object']).columns.tolist()\n",
        "print(df[list].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Columns not included are name, overview, backdrop_path, homepage, original_name, poster_path, tagline, languages, spoken_languages,production_countries, and cleaned_overview\n",
        "encode_cols =['original_language','type', 'status','created_by','networks','origin_country','production_companies']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['en',\n",
              " 'zh',\n",
              " 'ja',\n",
              " 'ko',\n",
              " 'de',\n",
              " 'fr',\n",
              " 'es',\n",
              " 'pt',\n",
              " 'ru',\n",
              " 'nl',\n",
              " 'ar',\n",
              " 'da',\n",
              " 'cn',\n",
              " 'th',\n",
              " 'tr',\n",
              " 'it',\n",
              " 'hi',\n",
              " 'sv',\n",
              " 'cs',\n",
              " 'no']"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating a list of the top 20 values in the original_language column\n",
        "top_20_original_language = df['original_language'].value_counts(ascending = False).head(20).index.tolist()\n",
        "top_20_original_language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating one-hot encoded columns for original_language\n",
        "for i in top_20_original_language:\n",
        "    name = 'original-language_' + i\n",
        "    df[name] = np.where(df['original_language'] == i, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'name', 'number_of_seasons', 'number_of_episodes', 'vote_count',\n",
              "       'vote_average', 'adult', 'backdrop_path', 'first_air_date',\n",
              "       'last_air_date', 'homepage', 'in_production', 'original_name',\n",
              "       'popularity', 'poster_path', 'type', 'status', 'tagline', 'created_by',\n",
              "       'languages', 'networks', 'origin_country', 'spoken_languages',\n",
              "       'production_companies', 'production_countries', 'episode_run_time',\n",
              "       'cleaned_overview', 'Action & Adventure', 'Animation', 'Comedy',\n",
              "       'Crime', 'Documentary', 'Drama', 'Family', 'History', 'Kids', 'Music',\n",
              "       'Musical', 'Mystery', 'News', 'Reality', 'Romance', 'Sci-Fi & Fantasy',\n",
              "       'Soap', 'Talk', 'Unknown', 'War & Politics', 'Western',\n",
              "       'original-language_en', 'original-language_zh', 'original-language_ja',\n",
              "       'original-language_ko', 'original-language_de', 'original-language_fr',\n",
              "       'original-language_es', 'original-language_pt', 'original-language_ru',\n",
              "       'original-language_nl', 'original-language_ar', 'original-language_da',\n",
              "       'original-language_cn', 'original-language_th', 'original-language_tr',\n",
              "       'original-language_it', 'original-language_hi', 'original-language_sv',\n",
              "       'original-language_cs', 'original-language_no'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Removing the original_language column from df and encode_cols\n",
        "df.drop(columns = ['original_language'], inplace = True)\n",
        "encode_cols.remove('original_language')\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Shotaro Ishinomori',\n",
              " 'John de Mol',\n",
              " 'Adrián Suar',\n",
              " 'Simon Fuller',\n",
              " 'Ekta Kapoor',\n",
              " 'Na Young-seok',\n",
              " 'Yang Li-Hua',\n",
              " 'Joseph Barbera, William Hanna',\n",
              " 'R.J. Nuevas',\n",
              " 'Mark Burnett']"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating a list of the top 10 values in the created_by column\n",
        "top_10_created_by = df['created_by'].value_counts(ascending = False).head(10).index.tolist()\n",
        "top_10_created_by"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating one-hot encoded columns for created_by\n",
        "for i in top_10_created_by:\n",
        "    name = 'created-by_' + i\n",
        "    df[name] = np.where(df['created_by'] == i, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'name', 'number_of_seasons', 'number_of_episodes', 'vote_count',\n",
              "       'vote_average', 'adult', 'backdrop_path', 'first_air_date',\n",
              "       'last_air_date', 'homepage', 'in_production', 'original_name',\n",
              "       'popularity', 'poster_path', 'type', 'status', 'tagline', 'languages',\n",
              "       'networks', 'origin_country', 'spoken_languages',\n",
              "       'production_companies', 'production_countries', 'episode_run_time',\n",
              "       'cleaned_overview', 'Action & Adventure', 'Animation', 'Comedy',\n",
              "       'Crime', 'Documentary', 'Drama', 'Family', 'History', 'Kids', 'Music',\n",
              "       'Musical', 'Mystery', 'News', 'Reality', 'Romance', 'Sci-Fi & Fantasy',\n",
              "       'Soap', 'Talk', 'Unknown', 'War & Politics', 'Western',\n",
              "       'original-language_en', 'original-language_zh', 'original-language_ja',\n",
              "       'original-language_ko', 'original-language_de', 'original-language_fr',\n",
              "       'original-language_es', 'original-language_pt', 'original-language_ru',\n",
              "       'original-language_nl', 'original-language_ar', 'original-language_da',\n",
              "       'original-language_cn', 'original-language_th', 'original-language_tr',\n",
              "       'original-language_it', 'original-language_hi', 'original-language_sv',\n",
              "       'original-language_cs', 'original-language_no',\n",
              "       'created-by_Shotaro Ishinomori', 'created-by_John de Mol',\n",
              "       'created-by_Adrián Suar', 'created-by_Simon Fuller',\n",
              "       'created-by_Ekta Kapoor', 'created-by_Na Young-seok',\n",
              "       'created-by_Yang Li-Hua', 'created-by_Joseph Barbera, William Hanna',\n",
              "       'created-by_R.J. Nuevas', 'created-by_Mark Burnett'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Removing the created_by column from df and encode_cols\n",
        "df.drop(columns = ['created_by'], inplace = True)\n",
        "encode_cols.remove('created_by')\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['BBC One',\n",
              " 'YouTube',\n",
              " 'Netflix',\n",
              " 'ITV1',\n",
              " 'BBC Two',\n",
              " 'ABC',\n",
              " 'NBC',\n",
              " 'TVB Jade',\n",
              " 'CBS',\n",
              " 'Channel 4',\n",
              " 'ZDF']"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating a list of the top 11 values in the networks column\n",
        "top_11_networks = df['networks'].value_counts(ascending = False).head(11).index.tolist()\n",
        "top_11_networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating one-hot encoded columns for networks\n",
        "for i in top_11_networks:\n",
        "    name = 'networks_' + i\n",
        "    df[name] = np.where(df['networks'] == i, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'name', 'number_of_seasons', 'number_of_episodes', 'vote_count',\n",
              "       'vote_average', 'adult', 'backdrop_path', 'first_air_date',\n",
              "       'last_air_date', 'homepage', 'in_production', 'original_name',\n",
              "       'popularity', 'poster_path', 'type', 'status', 'tagline', 'languages',\n",
              "       'origin_country', 'spoken_languages', 'production_companies',\n",
              "       'production_countries', 'episode_run_time', 'cleaned_overview',\n",
              "       'Action & Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary',\n",
              "       'Drama', 'Family', 'History', 'Kids', 'Music', 'Musical', 'Mystery',\n",
              "       'News', 'Reality', 'Romance', 'Sci-Fi & Fantasy', 'Soap', 'Talk',\n",
              "       'Unknown', 'War & Politics', 'Western', 'original-language_en',\n",
              "       'original-language_zh', 'original-language_ja', 'original-language_ko',\n",
              "       'original-language_de', 'original-language_fr', 'original-language_es',\n",
              "       'original-language_pt', 'original-language_ru', 'original-language_nl',\n",
              "       'original-language_ar', 'original-language_da', 'original-language_cn',\n",
              "       'original-language_th', 'original-language_tr', 'original-language_it',\n",
              "       'original-language_hi', 'original-language_sv', 'original-language_cs',\n",
              "       'original-language_no', 'created-by_Shotaro Ishinomori',\n",
              "       'created-by_John de Mol', 'created-by_Adrián Suar',\n",
              "       'created-by_Simon Fuller', 'created-by_Ekta Kapoor',\n",
              "       'created-by_Na Young-seok', 'created-by_Yang Li-Hua',\n",
              "       'created-by_Joseph Barbera, William Hanna', 'created-by_R.J. Nuevas',\n",
              "       'created-by_Mark Burnett', 'networks_BBC One', 'networks_YouTube',\n",
              "       'networks_Netflix', 'networks_ITV1', 'networks_BBC Two', 'networks_ABC',\n",
              "       'networks_NBC', 'networks_TVB Jade', 'networks_CBS',\n",
              "       'networks_Channel 4', 'networks_ZDF'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Removing the networks column from df and encode_cols\n",
        "df.drop(columns = ['networks'], inplace = True)\n",
        "encode_cols.remove('networks')\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['US',\n",
              " 'JP',\n",
              " 'GB',\n",
              " 'CN',\n",
              " 'DE',\n",
              " 'KR',\n",
              " 'CA',\n",
              " 'FR',\n",
              " 'AU',\n",
              " 'BR',\n",
              " 'NL',\n",
              " 'RU',\n",
              " 'ES',\n",
              " 'TH',\n",
              " 'HK',\n",
              " 'IN',\n",
              " 'DK',\n",
              " 'PH',\n",
              " 'IT',\n",
              " 'TR',\n",
              " 'SE',\n",
              " 'NO',\n",
              " 'TW',\n",
              " 'BE',\n",
              " 'CZ',\n",
              " 'MX']"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating a list of the top 10 values in the origin_country column\n",
        "top_26_origin_country = df['origin_country'].value_counts(ascending = False).head(26).index.tolist()\n",
        "top_26_origin_country"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/4070112400.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['origin_country'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/4070112400.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['origin_country'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/4070112400.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['origin_country'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/4070112400.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['origin_country'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/4070112400.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['origin_country'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/4070112400.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['origin_country'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/4070112400.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['origin_country'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/4070112400.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['origin_country'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/4070112400.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['origin_country'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/4070112400.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['origin_country'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/4070112400.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['origin_country'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/4070112400.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['origin_country'] == i, 1, 0)\n"
          ]
        }
      ],
      "source": [
        "# Creating one-hot encoded columns for origin_country\n",
        "for i in top_26_origin_country:\n",
        "    name = 'origin-country_' + i\n",
        "    df[name] = np.where(df['origin_country'] == i, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'name', 'number_of_seasons', 'number_of_episodes', 'vote_count',\n",
              "       'vote_average', 'adult', 'backdrop_path', 'first_air_date',\n",
              "       'last_air_date',\n",
              "       ...\n",
              "       'origin-country_DK', 'origin-country_PH', 'origin-country_IT',\n",
              "       'origin-country_TR', 'origin-country_SE', 'origin-country_NO',\n",
              "       'origin-country_TW', 'origin-country_BE', 'origin-country_CZ',\n",
              "       'origin-country_MX'],\n",
              "      dtype='object', length=112)"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Removing the origin_country column from df and encode_cols\n",
        "df.drop(columns = ['origin_country'], inplace = True)\n",
        "encode_cols.remove('origin_country')\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['TVB',\n",
              " 'BBC',\n",
              " 'Estúdios Globo',\n",
              " 'NHK',\n",
              " 'DR TV',\n",
              " 'TV 2',\n",
              " 'Televisa',\n",
              " 'GMA Entertainment Group',\n",
              " 'Česká televize',\n",
              " 'ATV Enterprises Limited']"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating a list of the top 10 values in the production_companies column\n",
        "top_10_production_companies = df['production_companies'].value_counts(ascending = False).head(10).index.tolist()\n",
        "top_10_production_companies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/2157461572.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['production_companies'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/2157461572.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['production_companies'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/2157461572.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['production_companies'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/2157461572.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['production_companies'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/2157461572.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['production_companies'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/2157461572.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['production_companies'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/2157461572.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['production_companies'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/2157461572.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['production_companies'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/2157461572.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['production_companies'] == i, 1, 0)\n",
            "/var/folders/m4/60ljkntj7gs489xq6yv_ghnm0000gn/T/ipykernel_2070/2157461572.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = np.where(df['production_companies'] == i, 1, 0)\n"
          ]
        }
      ],
      "source": [
        "# Creating one-hot encoded columns for production_companies\n",
        "for i in top_10_production_companies:\n",
        "    name = 'production-companies_' + i\n",
        "    df[name] = np.where(df['production_companies'] == i, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'name', 'number_of_seasons', 'number_of_episodes', 'vote_count',\n",
              "       'vote_average', 'adult', 'backdrop_path', 'first_air_date',\n",
              "       'last_air_date',\n",
              "       ...\n",
              "       'production-companies_TVB', 'production-companies_BBC',\n",
              "       'production-companies_Estúdios Globo', 'production-companies_NHK',\n",
              "       'production-companies_DR TV', 'production-companies_TV 2',\n",
              "       'production-companies_Televisa',\n",
              "       'production-companies_GMA Entertainment Group',\n",
              "       'production-companies_Česká televize',\n",
              "       'production-companies_ATV Enterprises Limited'],\n",
              "      dtype='object', length=121)"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Removing the production_companies column from df and encode_cols\n",
        "df.drop(columns = ['production_companies'], inplace = True)\n",
        "encode_cols.remove('production_companies')\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'name', 'number_of_seasons', 'number_of_episodes', 'vote_count',\n",
              "       'vote_average', 'adult', 'backdrop_path', 'first_air_date',\n",
              "       'last_air_date',\n",
              "       ...\n",
              "       'type_Reality', 'type_Scripted', 'type_Talk Show', 'type_Video',\n",
              "       'status_Canceled', 'status_Ended', 'status_In Production',\n",
              "       'status_Pilot', 'status_Planned', 'status_Returning Series'],\n",
              "      dtype='object', length=134)"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# One-hot encoding remaining columns\n",
        "for colname in encode_cols:\n",
        "    df_encoded = pd.get_dummies(df[colname], prefix=colname+'')\n",
        "    df = df.join(df_encoded)\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'name', 'number_of_seasons', 'number_of_episodes', 'vote_count',\n",
              "       'vote_average', 'adult', 'backdrop_path', 'first_air_date',\n",
              "       'last_air_date',\n",
              "       ...\n",
              "       'type_Reality', 'type_Scripted', 'type_Talk Show', 'type_Video',\n",
              "       'status_Canceled', 'status_Ended', 'status_In Production',\n",
              "       'status_Pilot', 'status_Planned', 'status_Returning Series'],\n",
              "      dtype='object', length=132)"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Removing remaining original cols from df\n",
        "df.drop(columns=encode_cols,axis=1,inplace=True)\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>number_of_seasons</th>\n",
              "      <th>number_of_episodes</th>\n",
              "      <th>vote_count</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>adult</th>\n",
              "      <th>backdrop_path</th>\n",
              "      <th>first_air_date</th>\n",
              "      <th>last_air_date</th>\n",
              "      <th>...</th>\n",
              "      <th>type_Reality</th>\n",
              "      <th>type_Scripted</th>\n",
              "      <th>type_Talk Show</th>\n",
              "      <th>type_Video</th>\n",
              "      <th>status_Canceled</th>\n",
              "      <th>status_Ended</th>\n",
              "      <th>status_In Production</th>\n",
              "      <th>status_Pilot</th>\n",
              "      <th>status_Planned</th>\n",
              "      <th>status_Returning Series</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1399</td>\n",
              "      <td>Game of Thrones</td>\n",
              "      <td>8</td>\n",
              "      <td>73</td>\n",
              "      <td>21857</td>\n",
              "      <td>8.442</td>\n",
              "      <td>False</td>\n",
              "      <td>/2OMB0ynKlyIenMJWI2Dy9IWT4c.jpg</td>\n",
              "      <td>2011-04-17</td>\n",
              "      <td>2019-05-19</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>71446</td>\n",
              "      <td>Money Heist</td>\n",
              "      <td>3</td>\n",
              "      <td>41</td>\n",
              "      <td>17836</td>\n",
              "      <td>8.257</td>\n",
              "      <td>False</td>\n",
              "      <td>/gFZriCkpJYsApPZEF3jhxL4yLzG.jpg</td>\n",
              "      <td>2017-05-02</td>\n",
              "      <td>2021-12-03</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>66732</td>\n",
              "      <td>Stranger Things</td>\n",
              "      <td>4</td>\n",
              "      <td>34</td>\n",
              "      <td>16161</td>\n",
              "      <td>8.624</td>\n",
              "      <td>False</td>\n",
              "      <td>/2MaumbgBlW1NoPo3ZJO38A6v7OS.jpg</td>\n",
              "      <td>2016-07-15</td>\n",
              "      <td>2022-07-01</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1402</td>\n",
              "      <td>The Walking Dead</td>\n",
              "      <td>11</td>\n",
              "      <td>177</td>\n",
              "      <td>15432</td>\n",
              "      <td>8.121</td>\n",
              "      <td>False</td>\n",
              "      <td>/x4salpjB11umlUOltfNvSSrjSXm.jpg</td>\n",
              "      <td>2010-10-31</td>\n",
              "      <td>2022-11-20</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63174</td>\n",
              "      <td>Lucifer</td>\n",
              "      <td>6</td>\n",
              "      <td>93</td>\n",
              "      <td>13870</td>\n",
              "      <td>8.486</td>\n",
              "      <td>False</td>\n",
              "      <td>/aDBRtunw49UF4XmqfyNuD9nlYIu.jpg</td>\n",
              "      <td>2016-01-25</td>\n",
              "      <td>2021-09-10</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>69050</td>\n",
              "      <td>Riverdale</td>\n",
              "      <td>7</td>\n",
              "      <td>137</td>\n",
              "      <td>13180</td>\n",
              "      <td>8.479</td>\n",
              "      <td>False</td>\n",
              "      <td>/soQgquPkLmUu9eKLJJzuA4KZDyi.jpg</td>\n",
              "      <td>2017-01-26</td>\n",
              "      <td>2023-08-23</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>93405</td>\n",
              "      <td>Squid Game</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>13053</td>\n",
              "      <td>7.831</td>\n",
              "      <td>False</td>\n",
              "      <td>/2meX1nMdScFOoV4370rqHWKmXhY.jpg</td>\n",
              "      <td>2021-09-17</td>\n",
              "      <td>2021-09-17</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1396</td>\n",
              "      <td>Breaking Bad</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>12398</td>\n",
              "      <td>8.890</td>\n",
              "      <td>False</td>\n",
              "      <td>/tsRy63Mu5cu8etL1X7ZLyf7UP1M.jpg</td>\n",
              "      <td>2008-01-20</td>\n",
              "      <td>2013-09-29</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>71712</td>\n",
              "      <td>The Good Doctor</td>\n",
              "      <td>6</td>\n",
              "      <td>116</td>\n",
              "      <td>11768</td>\n",
              "      <td>8.503</td>\n",
              "      <td>False</td>\n",
              "      <td>/xXRsKNJHTOGrs5wfYAxkbM2RiyT.jpg</td>\n",
              "      <td>2017-09-25</td>\n",
              "      <td>2023-05-01</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>85271</td>\n",
              "      <td>WandaVision</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>11308</td>\n",
              "      <td>8.300</td>\n",
              "      <td>False</td>\n",
              "      <td>/lOr9NKxh4vMweufMOUDJjJhCRHW.jpg</td>\n",
              "      <td>2021-01-15</td>\n",
              "      <td>2021-03-05</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 132 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      id              name  number_of_seasons  number_of_episodes  vote_count  \\\n",
              "0   1399   Game of Thrones                  8                  73       21857   \n",
              "1  71446       Money Heist                  3                  41       17836   \n",
              "2  66732   Stranger Things                  4                  34       16161   \n",
              "3   1402  The Walking Dead                 11                 177       15432   \n",
              "4  63174           Lucifer                  6                  93       13870   \n",
              "5  69050         Riverdale                  7                 137       13180   \n",
              "6  93405        Squid Game                  2                   9       13053   \n",
              "7   1396      Breaking Bad                  5                  62       12398   \n",
              "8  71712   The Good Doctor                  6                 116       11768   \n",
              "9  85271       WandaVision                  1                   9       11308   \n",
              "\n",
              "   vote_average  adult                     backdrop_path first_air_date  \\\n",
              "0         8.442  False   /2OMB0ynKlyIenMJWI2Dy9IWT4c.jpg     2011-04-17   \n",
              "1         8.257  False  /gFZriCkpJYsApPZEF3jhxL4yLzG.jpg     2017-05-02   \n",
              "2         8.624  False  /2MaumbgBlW1NoPo3ZJO38A6v7OS.jpg     2016-07-15   \n",
              "3         8.121  False  /x4salpjB11umlUOltfNvSSrjSXm.jpg     2010-10-31   \n",
              "4         8.486  False  /aDBRtunw49UF4XmqfyNuD9nlYIu.jpg     2016-01-25   \n",
              "5         8.479  False  /soQgquPkLmUu9eKLJJzuA4KZDyi.jpg     2017-01-26   \n",
              "6         7.831  False  /2meX1nMdScFOoV4370rqHWKmXhY.jpg     2021-09-17   \n",
              "7         8.890  False  /tsRy63Mu5cu8etL1X7ZLyf7UP1M.jpg     2008-01-20   \n",
              "8         8.503  False  /xXRsKNJHTOGrs5wfYAxkbM2RiyT.jpg     2017-09-25   \n",
              "9         8.300  False  /lOr9NKxh4vMweufMOUDJjJhCRHW.jpg     2021-01-15   \n",
              "\n",
              "  last_air_date  ... type_Reality  type_Scripted type_Talk Show  type_Video  \\\n",
              "0    2019-05-19  ...        False           True          False       False   \n",
              "1    2021-12-03  ...        False           True          False       False   \n",
              "2    2022-07-01  ...        False           True          False       False   \n",
              "3    2022-11-20  ...        False           True          False       False   \n",
              "4    2021-09-10  ...        False           True          False       False   \n",
              "5    2023-08-23  ...        False           True          False       False   \n",
              "6    2021-09-17  ...        False           True          False       False   \n",
              "7    2013-09-29  ...        False           True          False       False   \n",
              "8    2023-05-01  ...        False           True          False       False   \n",
              "9    2021-03-05  ...        False          False          False       False   \n",
              "\n",
              "  status_Canceled status_Ended status_In Production status_Pilot  \\\n",
              "0           False         True                False        False   \n",
              "1           False         True                False        False   \n",
              "2           False        False                False        False   \n",
              "3           False         True                False        False   \n",
              "4           False         True                False        False   \n",
              "5           False         True                False        False   \n",
              "6           False        False                False        False   \n",
              "7           False         True                False        False   \n",
              "8           False        False                False        False   \n",
              "9           False         True                False        False   \n",
              "\n",
              "  status_Planned  status_Returning Series  \n",
              "0          False                    False  \n",
              "1          False                    False  \n",
              "2          False                     True  \n",
              "3          False                    False  \n",
              "4          False                    False  \n",
              "5          False                    False  \n",
              "6          False                     True  \n",
              "7          False                    False  \n",
              "8          False                     True  \n",
              "9          False                    False  \n",
              "\n",
              "[10 rows x 132 columns]"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UqEeYDooDIS"
      },
      "source": [
        "# EDA"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
